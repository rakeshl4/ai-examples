{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate LLM responses with Microsoft Semantic Kernel\n",
    "\n",
    "This notebook demonstrates how to evaluate the quality of responses generated by a large language model (LLM) using Microsoft Semantic Kernel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Install NuGet packages\n",
    "\n",
    "To get started with Semantic Kernel, you need to install the required NuGet packages. These packages provide the core functionality for interacting with AI models and managing environment variables. Specifically:\n",
    "- `Microsoft.SemanticKernel` enables you to build and run AI-powered workflows.\n",
    "- `DotNetEnv` allows you to load environment variables from a `.env` file, making it easier to manage secrets and configuration settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>DotNetEnv, 3.1.0</span></li><li><span>Microsoft.SemanticKernel, 1.23.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Import Semantic Kernel\n",
    "#r \"nuget: Microsoft.SemanticKernel, 1.23.0\"\n",
    "#r \"nuget: DotNetEnv, 3.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Read environment variables\n",
    "\n",
    "  In this step, we load these variables from a `.env` file (if present) so that they can be accessed by the application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded environment variables from d:\\personal\\ai-examples\\03-evaluate-llm-response\\..\\.env\r\n"
     ]
    }
   ],
   "source": [
    "using DotNetEnv;\n",
    "using System.IO;\n",
    "\n",
    "var envFilePath = Path.Combine(Environment.CurrentDirectory, \"..\", \".env\");\n",
    "if (File.Exists(envFilePath))\n",
    "{\n",
    "    Env.Load(envFilePath);\n",
    "    Console.WriteLine($\"Loaded environment variables from {envFilePath}\");\n",
    "}\n",
    "else\n",
    "{\n",
    "    Console.WriteLine($\"No .env file found at {envFilePath}\");\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Instantiate the Kernel\n",
    "\n",
    "The Semantic Kernel is the core component that orchestrates AI services and plugins. In this step, we create and configure a Kernel instance, which will be used to interact with AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.SemanticKernel;\n",
    "using Kernel = Microsoft.SemanticKernel.Kernel;\n",
    "\n",
    "//Create Kernel builder\n",
    "var builder = Kernel.CreateBuilder();\n",
    "\n",
    "// Configure AI service credentials used by the kernel\n",
    "var (useAzureOpenAI, model, azureEndpoint, apiKey, orgId) = //read from environment variables\n",
    "    (Environment.GetEnvironmentVariable(\"USE_AZURE_OPENAI\") == \"true\",\n",
    "    Environment.GetEnvironmentVariable(\"MODEL\"),\n",
    "    Environment.GetEnvironmentVariable(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    Environment.GetEnvironmentVariable(\"AZURE_OPENAI_API_KEY\"),\n",
    "    Environment.GetEnvironmentVariable(\"OPENAI_ORG_ID\"));\n",
    "\n",
    "if (useAzureOpenAI)\n",
    "    builder.AddAzureOpenAIChatCompletion(model, azureEndpoint, apiKey);\n",
    "else\n",
    "    builder.AddOpenAIChatCompletion(model, apiKey, orgId);\n",
    "\n",
    "var kernel = builder.Build();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Call the Kernel\n",
    "\n",
    "Create the prompt to evaluate the LLM response. The prompt should include instructions, the response you want to evaluate and any additional context that will help the model understand what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: {\n",
      "  'intent_resolution': 5,\n",
      "  'reason': 'The response directly answers the user's question with the precise fact that Paris is the capital of France.'\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "var prompt = @\"\n",
    "You are an AI assistant. You will be given the definition of an evaluation metric for assessing the quality of an answer in a question-answering task. Your job is to compute an accurate evaluation score using the provided evaluation metric. Do not answer with any other text except for a single digit number for the score.\n",
    "\n",
    "Intent Resolution: This metric measures how well the response addresses the user's intent. \n",
    "You response should have a score and a reason for the score in the following format: \n",
    "{\n",
    "  'intent_resolution': <score>,\n",
    "  'reason': '<explanation of the score>'\n",
    "}\n",
    "\n",
    "The score should be a number between 1 and 5, where 1 means the response does not address the user's intent at all, and 5 means the response fully addresses the user's intent.\n",
    "\n",
    "Example:\n",
    "user: What are the opening hours of the Eiffel Tower?\n",
    "assistant: Opening hours of the Eiffel Tower are 9:00 AM to 11:00 PM.\n",
    "score:{\n",
    "  'intent_resolution': 5,\n",
    "  'reason': 'The response directly answers the user's question with clear information.'\n",
    "}\n",
    "\n",
    "Example:\n",
    "user: Plan a trip to Paris.\n",
    "assistant: Paris is a beautiful city with many attractions.\n",
    "score: {\n",
    "  'intent_resolution': 2,\n",
    "  'reason': 'The response does not provide specific information about planning a trip, such as travel dates or activities.'\n",
    "}\n",
    "Example:\n",
    "user: Book a flight to New York.\n",
    "assistant: The Eiffel Tower is a famous landmark in Paris, France, attracting millions of visitors each year.\n",
    "score: {\n",
    "  'intent_resolution': 1,\n",
    "  'reason': 'The\n",
    "   response is completely off-topic and does not address the user's request to book a flight.'\n",
    "}\n",
    "\n",
    "context: {{$Context}}\n",
    "question: {{$Question}}\n",
    "answer: {{$Answer}}\n",
    "score:\n",
    "\"; \n",
    "\n",
    " KernelArguments arguments = new() { { \"Context\",  \"Paris is a beautiful city with many attractions.\" }, \n",
    "                                      { \"Question\", \"What is the capital of France?\" }, \n",
    "                                      { \"Answer\", \"The capital of France is Paris.\" } };\n",
    "var response = await kernel.InvokePromptAsync(prompt,arguments);\n",
    "\n",
    "Console.WriteLine($\"Response: {response}\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
